{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathered Notebook\n",
    "\n",
    "This notebook was generated by the Gather Extension. The intent is that it contains only the code and cells required to produce the same results as the cell originally selected for gathering. Please note that the Python analysis is quite conservative, so if it is unsure whether a line of code is necessary for execution, it will err on the side of including it.\n",
    "\n",
    "**Please let us know if you are satisfied with what was gathered [here](https://aka.ms/gatherfeedback).**\n",
    "\n",
    "Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./guardian_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].replace('\\n', '', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80540\n"
     ]
    }
   ],
   "source": [
    "text_list = df[\"text\"].to_list()\n",
    "\n",
    "all_text = \" \".join(text_list)\n",
    "add_space = re.sub(r'\\b\\.(?=\\w)', \". \", all_text)\n",
    "print(len(add_space))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alltext.txt', 'w') as f:\n",
    "    f.write(add_space)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Friends', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Firsat', 'NNP'),\n",
       " ('Dag', 'NNP'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('25-year-old', 'JJ'),\n",
       " ('Kurdish', 'NNP'),\n",
       " ('asylum', 'NN'),\n",
       " ('seeker', 'NN'),\n",
       " (',', ','),\n",
       " ('said', 'VBD'),\n",
       " ('he', 'PRP'),\n",
       " ('came', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('UK', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('escape', 'VB'),\n",
       " ('violence', 'NN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = word_tokenize(add_space)\n",
    "pos_text = nltk.pos_tag(tokenized_text)\n",
    "# nltk.help.upenn_tagset('NN.*')\n",
    "print(len(pos_text))\n",
    "pos_text[:20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juancarlos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stops = stopwords.words('english')\n",
    "\", \".join(english_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Friends', 'NNS'),\n",
       " ('Firsat', 'NNP'),\n",
       " ('Dag', 'NNP'),\n",
       " (',', ','),\n",
       " ('25-year-old', 'JJ'),\n",
       " ('Kurdish', 'NNP'),\n",
       " ('asylum', 'NN'),\n",
       " ('seeker', 'NN'),\n",
       " (',', ','),\n",
       " ('said', 'VBD')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopless_tuples =[]\n",
    "\n",
    "for tuple in pos_text:\n",
    "    if tuple[0].lower() not in english_stops:\n",
    "        stopless_tuples.append(tuple)\n",
    "print(len(stopless_tuples))\n",
    "stopless_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = {}\n",
    "\n",
    "# for word in all_text:\n",
    "#     if word.lower() not in english_stops:\n",
    "#         counts[word] = counts.get(word, 0) + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some of the \"counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_df = pd.DataFrame.from_dict(counts, orient='index', columns=['count'])\n",
    "# peak_df.head(20).sort_values(\"count\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Friends', 'NNS'),\n",
       " ('Firsat', 'NNP'),\n",
       " ('Dag', 'NNP'),\n",
       " ('25-year-old', 'JJ'),\n",
       " ('Kurdish', 'NNP'),\n",
       " ('asylum', 'NN'),\n",
       " ('seeker', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('came', 'VBD'),\n",
       " ('UK', 'NNP'),\n",
       " ('escape', 'VB'),\n",
       " ('violence', 'NN'),\n",
       " ('Instead', 'RB'),\n",
       " ('stabbed', 'VBN'),\n",
       " ('death', 'NN'),\n",
       " ('park', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('home', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('isolated', 'JJ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vocab = []\n",
    "exclude = [\",\", \".\",\"“\", \"”\", \"‘\", \"’\" ,\"-webkit\", \"-ms\", \"flex\", \"email-\", \"nowrap\", \"width:\", \"height:\"]\n",
    "for tuple in stopless_tuples:\n",
    "     if tuple[0] not in exclude:\n",
    "        clean_vocab.append(tuple)\n",
    "print(len(clean_vocab))\n",
    "clean_vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "\n",
    "for tuple in clean_vocab:\n",
    "    if tuple in counts:\n",
    "        counts[tuple] += 1\n",
    "    else:\n",
    "        counts[tuple] = 1\n",
    "\n",
    "clean_vocab = [(tuple[0], tuple[1], count) for tuple, count in counts.items()]\n",
    "print(len(clean_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3743\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for tuple in clean_vocab:\n",
    "    if not tuple[0].isdigit():\n",
    "        vocab.append(tuple)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Friends', 'NNS', 1),\n",
       " ('Firsat', 'NNP', 2),\n",
       " ('Dag', 'NNP', 3),\n",
       " ('25-year-old', 'JJ', 2),\n",
       " ('Kurdish', 'NNP', 2),\n",
       " ('asylum', 'NN', 16),\n",
       " ('seeker', 'NN', 2),\n",
       " ('said', 'VBD', 15),\n",
       " ('came', 'VBD', 8),\n",
       " ('UK', 'NNP', 17),\n",
       " ('escape', 'VB', 3),\n",
       " ('violence', 'NN', 2),\n",
       " ('Instead', 'RB', 3),\n",
       " ('stabbed', 'VBN', 2),\n",
       " ('death', 'NN', 4),\n",
       " ('park', 'NN', 2),\n",
       " ('way', 'NN', 11),\n",
       " ('home', 'NN', 7),\n",
       " ('night', 'NN', 3),\n",
       " ('isolated', 'JJ', 2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>Said</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>sexy</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>Maybe</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>try</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>cycling</td>\n",
       "      <td>VBG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>Oliver</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>Wainwright</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>architecture</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>design</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>critic</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  POS  Count\n",
       "3733          Said  NNP      1\n",
       "3734          sexy   JJ      1\n",
       "3735         Maybe   RB      1\n",
       "3736           try   VB      1\n",
       "3737       cycling  VBG      1\n",
       "3738        Oliver  NNP      1\n",
       "3739    Wainwright  NNP      1\n",
       "3740  architecture   NN      1\n",
       "3741        design   NN      1\n",
       "3742        critic   NN      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek = pd.DataFrame(vocab, columns=['Word', 'POS', 'Count'])\n",
    "peek.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Friends</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Firsat</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dag</td>\n",
       "      <td>NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-year-old</td>\n",
       "      <td>JJ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kurdish</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>Oliver</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>Wainwright</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>architecture</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>design</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>critic</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3743 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  POS  Count\n",
       "0          Friends  NNS      1\n",
       "1           Firsat  NNP      2\n",
       "2              Dag  NNP      3\n",
       "3      25-year-old   JJ      2\n",
       "4          Kurdish  NNP      2\n",
       "...            ...  ...    ...\n",
       "3738        Oliver  NNP      1\n",
       "3739    Wainwright  NNP      1\n",
       "3740  architecture   NN      1\n",
       "3741        design   NN      1\n",
       "3742        critic   NN      1\n",
       "\n",
       "[3743 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "1. find if there is a difference between proper nouns and other capitalised words and lower case words that don't need to be capitalised\n",
    "2. export to .csv without index\n",
    "3. add extended name for POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('tuples.txt', 'w') as f:\n",
    "#     for t in vocab:\n",
    "#         f.write(str(t) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "exceptions = [t for t in vocab if t[0].startswith(\"-webkit-\")]\n",
    "print(len(exceptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_chars(s):\n",
    "#     return s.translate(str.maketrans(\" \", \" \", string.punctuation.replace(\"_\", \"\")))\n",
    "\n",
    "# clean_count = {replace_chars(k): v for k, v in counts.items()}\n",
    "# print(len(clean_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace(',', ' ').replace('.', ' '): v for k, v in counts.items()}\n",
    "\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace('“', '').replace('”', '').replace('‘', '').replace('’', ''): v for k, v in clean_count.items()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with capitalized words (potentially proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isupper()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with sterling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"£\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with \"–\" as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"–\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isdigit()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek = pd.DataFrame.from_dict(clean_count, orient='index', columns=['count'])\n",
    "# peek.sort_values(\"count\").tail(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary = sorted([ (v,k) for k,v in counts.items()], reverse=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorted list reveals that further refinement is going to be needed: The most common are probably only marginally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many at the bottom of the list (those less used) are not grammatical words and they need to be cleaned up. For example removing words in parenthesis, with hashtags, numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[-1000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_counts = {k: v for k, v in counts.items() if not (k.startswith('#') \n",
    "# or k.startswith('(')\n",
    "# or k.startswith('$')\n",
    "# or k.startswith('£')\n",
    "# or k.startswith('\\''))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sorted_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(clean_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in list(clean_counts)[900:1000]:\n",
    "#     print (\"key {}, value {} \".format(x,  clean_counts[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [(k, v) for k, v in clean_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(data, columns=['key', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.sort_values(by='value', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbba1214f6436c1b9df455eb4b634c6f3489084cc9221bb041863e864fbbb981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
