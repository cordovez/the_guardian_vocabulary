{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathered Notebook\n",
    "\n",
    "This notebook was generated by the Gather Extension. The intent is that it contains only the code and cells required to produce the same results as the cell originally selected for gathering. Please note that the Python analysis is quite conservative, so if it is unsure whether a line of code is necessary for execution, it will err on the side of including it.\n",
    "\n",
    "**Please let us know if you are satisfied with what was gathered [here](https://aka.ms/gatherfeedback).**\n",
    "\n",
    "Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./guardian_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = df['article'].replace('\\n', '', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259276\n"
     ]
    }
   ],
   "source": [
    "text_list = df[\"article\"].to_list()\n",
    "\n",
    "all_text = \" \".join(text_list)\n",
    "add_space = re.sub(r'\\b\\.(?=\\w)', \". \", all_text)\n",
    "print(len(add_space))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alltext.txt', 'w') as f:\n",
    "    f.write(add_space)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('“', 'NN'),\n",
       " ('You', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'JJ'),\n",
       " ('set', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pigeons', 'NNS'),\n",
       " (',', ','),\n",
       " ('”', 'NNP'),\n",
       " ('messaged', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('Tory', 'NNP'),\n",
       " ('MP', 'NNP'),\n",
       " ('after', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('interview', 'NN'),\n",
       " ('with', 'IN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = word_tokenize(add_space)\n",
    "pos_text = nltk.pos_tag(tokenized_text)\n",
    "# nltk.help.upenn_tagset('NN.*')\n",
    "print(len(pos_text))\n",
    "pos_text[:20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juancarlos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stops = stopwords.words('english')\n",
    "\", \".join(english_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('“', 'NN'),\n",
       " ('’', 'VBP'),\n",
       " ('set', 'VBN'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('pigeons', 'NNS'),\n",
       " (',', ','),\n",
       " ('”', 'NNP'),\n",
       " ('messaged', 'VBD'),\n",
       " ('Tory', 'NNP')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopless_tuples =[]\n",
    "\n",
    "for tuple in pos_text:\n",
    "    if tuple[0].lower() not in english_stops:\n",
    "        stopless_tuples.append(tuple)\n",
    "print(len(stopless_tuples))\n",
    "stopless_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = {}\n",
    "\n",
    "# for word in all_text:\n",
    "#     if word.lower() not in english_stops:\n",
    "#         counts[word] = counts.get(word, 0) + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some of the \"counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_df = pd.DataFrame.from_dict(counts, orient='index', columns=['count'])\n",
    "# peak_df.head(20).sort_values(\"count\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('set', 'VBN'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('pigeons', 'NNS'),\n",
       " ('messaged', 'VBD'),\n",
       " ('Tory', 'NNP'),\n",
       " ('MP', 'NNP'),\n",
       " ('interview', 'NN'),\n",
       " ('Liz', 'NNP'),\n",
       " ('Truss', 'NNP'),\n",
       " ('dropped', 'VBD'),\n",
       " ('Monday', 'NNP'),\n",
       " ('night', 'NN'),\n",
       " ('former', 'JJ'),\n",
       " ('prime', 'JJ'),\n",
       " ('minister', 'NN'),\n",
       " ('first', 'RB'),\n",
       " ('spoken', 'VBN'),\n",
       " ('intervention', 'NN'),\n",
       " ('since', 'IN')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vocab = []\n",
    "exclude = [\",\", \".\",\"“\", \"”\", \"‘\", \"’\" ,\"-webkit\", \"-ms\", \"flex\", \"email-\", \"nowrap\", \"width:\", \"height:\"]\n",
    "for tuple in stopless_tuples:\n",
    "     if tuple[0] not in exclude:\n",
    "        clean_vocab.append(tuple)\n",
    "print(len(clean_vocab))\n",
    "clean_vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8770\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "\n",
    "for tuple in clean_vocab:\n",
    "    if tuple in counts:\n",
    "        counts[tuple] += 1\n",
    "    else:\n",
    "        counts[tuple] = 1\n",
    "\n",
    "clean_vocab = [(tuple[0], tuple[1], count) for tuple, count in counts.items()]\n",
    "print(len(clean_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8658\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for tuple in clean_vocab:\n",
    "    if not tuple[0].isdigit():\n",
    "        vocab.append(tuple)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unless', 'IN', 1),\n",
       " ('change', 'VBP', 1),\n",
       " ('launch', 'NN', 1),\n",
       " ('report', 'VBP', 1),\n",
       " ('People', 'NNP', 1),\n",
       " ('approach.', 'NN', 1),\n",
       " ('humane', 'NN', 1),\n",
       " ('|', 'NNS', 1),\n",
       " ('Maya', 'NNP', 1),\n",
       " ('GoodfellowRead', 'NNP', 1),\n",
       " ('moreBut', 'VBD', 1),\n",
       " ('overwhelmingly', 'RB', 1),\n",
       " ('advocating', 'VBG', 1),\n",
       " ('mass', 'VB', 1),\n",
       " ('tactical', 'JJ', 1),\n",
       " ('forge', 'VB', 1),\n",
       " ('terrain', 'NN', 2),\n",
       " ('elites', 'NNS', 1),\n",
       " ('swing', 'VBG', 1),\n",
       " ('caging', 'VBG', 1),\n",
       " ('Recent', 'JJ', 1),\n",
       " ('backing', 'NN', 2),\n",
       " ('believing', 'VBG', 1),\n",
       " ('candidates', 'NNS', 2),\n",
       " ('out-of-date', 'JJ', 1),\n",
       " ('technocratic', 'NN', 1),\n",
       " ('paternalist', 'JJ', 1),\n",
       " ('twisted', 'JJ', 1),\n",
       " ('retain', 'VB', 1),\n",
       " ('monopoly', 'NN', 1),\n",
       " ('stopping', 'VBG', 1),\n",
       " ('entrants', 'NNS', 1),\n",
       " ('guaranteed', 'JJ', 1),\n",
       " ('periods', 'NNS', 1),\n",
       " ('voting', 'VBG', 2),\n",
       " ('nudge', 'NN', 1),\n",
       " ('waged', 'VBN', 1),\n",
       " ('combining', 'VBG', 1),\n",
       " ('inspiration', 'NN', 1),\n",
       " ('Scottish', 'NNP', 1),\n",
       " ('realised', 'VBD', 1),\n",
       " ('civic', 'NN', 1),\n",
       " ('maintained', 'VBN', 1),\n",
       " ('whatever', 'IN', 1),\n",
       " ('Starmer', 'NN', 1),\n",
       " ('bent', 'VBN', 1),\n",
       " ('Neal', 'NNP', 1),\n",
       " ('Lawson', 'NNP', 1),\n",
       " ('cross-party', 'JJ', 1),\n",
       " ('Compass', 'NNP', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>realised</td>\n",
       "      <td>VBD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>civic</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>maintained</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>whatever</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8652</th>\n",
       "      <td>Starmer</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>bent</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>Neal</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>Lawson</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>cross-party</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>Compass</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  POS  Count\n",
       "8648     realised  VBD      1\n",
       "8649        civic   NN      1\n",
       "8650   maintained  VBN      1\n",
       "8651     whatever   IN      1\n",
       "8652      Starmer   NN      1\n",
       "8653         bent  VBN      1\n",
       "8654         Neal  NNP      1\n",
       "8655       Lawson  NNP      1\n",
       "8656  cross-party   JJ      1\n",
       "8657      Compass  NNP      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek = pd.DataFrame(vocab, columns=['Word', 'POS', 'Count'])\n",
    "peek.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set</td>\n",
       "      <td>VBN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>among</td>\n",
       "      <td>IN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pigeons</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>messaged</td>\n",
       "      <td>VBD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>bent</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>Neal</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>Lawson</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>cross-party</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>Compass</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8658 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  POS  Count\n",
       "0             set  VBN      6\n",
       "1             cat   NN      2\n",
       "2           among   IN     21\n",
       "3         pigeons  NNS      1\n",
       "4        messaged  VBD      1\n",
       "...           ...  ...    ...\n",
       "8653         bent  VBN      1\n",
       "8654         Neal  NNP      1\n",
       "8655       Lawson  NNP      1\n",
       "8656  cross-party   JJ      1\n",
       "8657      Compass  NNP      1\n",
       "\n",
       "[8658 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "1. find if there is a difference between proper nouns and other capitalised words and lower case words that don't need to be capitalised\n",
    "2. export to .csv without index\n",
    "3. add extended name for POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('tuples.txt', 'w') as f:\n",
    "#     for t in vocab:\n",
    "#         f.write(str(t) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "exceptions = [t for t in vocab if t[0].startswith(\"-webkit-\")]\n",
    "print(len(exceptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_chars(s):\n",
    "#     return s.translate(str.maketrans(\" \", \" \", string.punctuation.replace(\"_\", \"\")))\n",
    "\n",
    "# clean_count = {replace_chars(k): v for k, v in counts.items()}\n",
    "# print(len(clean_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace(',', ' ').replace('.', ' '): v for k, v in counts.items()}\n",
    "\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace('“', '').replace('”', '').replace('‘', '').replace('’', ''): v for k, v in clean_count.items()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with capitalized words (potentially proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isupper()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with sterling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"£\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with \"–\" as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"–\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isdigit()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek = pd.DataFrame.from_dict(clean_count, orient='index', columns=['count'])\n",
    "# peek.sort_values(\"count\").tail(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary = sorted([ (v,k) for k,v in counts.items()], reverse=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorted list reveals that further refinement is going to be needed: The most common are probably only marginally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many at the bottom of the list (those less used) are not grammatical words and they need to be cleaned up. For example removing words in parenthesis, with hashtags, numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[-1000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_counts = {k: v for k, v in counts.items() if not (k.startswith('#') \n",
    "# or k.startswith('(')\n",
    "# or k.startswith('$')\n",
    "# or k.startswith('£')\n",
    "# or k.startswith('\\''))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10181\n"
     ]
    }
   ],
   "source": [
    "# print(len(sorted_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067\n"
     ]
    }
   ],
   "source": [
    "# print(len(clean_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in list(clean_counts)[900:1000]:\n",
    "#     print (\"key {}, value {} \".format(x,  clean_counts[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [(k, v) for k, v in clean_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(data, columns=['key', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.sort_values(by='value', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbba1214f6436c1b9df455eb4b634c6f3489084cc9221bb041863e864fbbb981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
