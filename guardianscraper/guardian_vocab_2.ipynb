{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathered Notebook\n",
    "\n",
    "This notebook was generated by the Gather Extension. The intent is that it contains only the code and cells required to produce the same results as the cell originally selected for gathering. Please note that the Python analysis is quite conservative, so if it is unsure whether a line of code is necessary for execution, it will err on the side of including it.\n",
    "\n",
    "**Please let us know if you are satisfied with what was gathered [here](https://aka.ms/gatherfeedback).**\n",
    "\n",
    "Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./guardian_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = df['article'].replace('\\n', '', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259276\n"
     ]
    }
   ],
   "source": [
    "text_list = df[\"article\"].to_list()\n",
    "\n",
    "all_text = \" \".join(text_list)\n",
    "add_space = re.sub(r'\\b\\.(?=\\w)', \". \", all_text)\n",
    "print(len(add_space))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('“', 'NN'),\n",
       " ('You', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('ve', 'JJ'),\n",
       " ('set', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pigeons', 'NNS'),\n",
       " (',', ','),\n",
       " ('”', 'NNP'),\n",
       " ('messaged', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('Tory', 'NNP'),\n",
       " ('MP', 'NNP'),\n",
       " ('after', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('interview', 'NN'),\n",
       " ('with', 'IN')]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = word_tokenize(add_space)\n",
    "pos_text = nltk.pos_tag(tokenized_text)\n",
    "# nltk.help.upenn_tagset('NN.*')\n",
    "print(len(pos_text))\n",
    "pos_text[:20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juancarlos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stops = stopwords.words('english')\n",
    "\", \".join(english_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('“', 'NN'),\n",
       " ('’', 'VBP'),\n",
       " ('set', 'VBN'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('pigeons', 'NNS'),\n",
       " (',', ','),\n",
       " ('”', 'NNP'),\n",
       " ('messaged', 'VBD'),\n",
       " ('Tory', 'NNP')]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopless_tuples =[]\n",
    "\n",
    "for tuple in pos_text:\n",
    "    if tuple[0].lower() not in english_stops:\n",
    "        stopless_tuples.append(tuple)\n",
    "print(len(stopless_tuples))\n",
    "stopless_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = {}\n",
    "\n",
    "# for word in all_text:\n",
    "#     if word.lower() not in english_stops:\n",
    "#         counts[word] = counts.get(word, 0) + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some of the \"counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_df = pd.DataFrame.from_dict(counts, orient='index', columns=['count'])\n",
    "# peak_df.head(20).sort_values(\"count\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('set', 'VBN'),\n",
       " ('cat', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('pigeons', 'NNS'),\n",
       " ('messaged', 'VBD'),\n",
       " ('Tory', 'NNP'),\n",
       " ('MP', 'NNP'),\n",
       " ('interview', 'NN'),\n",
       " ('Liz', 'NNP'),\n",
       " ('Truss', 'NNP'),\n",
       " ('dropped', 'VBD'),\n",
       " ('Monday', 'NNP'),\n",
       " ('night', 'NN'),\n",
       " ('former', 'JJ'),\n",
       " ('prime', 'JJ'),\n",
       " ('minister', 'NN'),\n",
       " ('first', 'RB'),\n",
       " ('spoken', 'VBN'),\n",
       " ('intervention', 'NN'),\n",
       " ('since', 'IN')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vocab = []\n",
    "exclude = [\",\", \".\",\"“\", \"”\", \"‘\", \"’\" ]\n",
    "for tuple in stopless_tuples:\n",
    "     if tuple[0] not in exclude:\n",
    "        clean_vocab.append(tuple)\n",
    "print(len(clean_vocab))\n",
    "clean_vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8770\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "\n",
    "for tuple in clean_vocab:\n",
    "    if tuple in counts:\n",
    "        counts[tuple] += 1\n",
    "    else:\n",
    "        counts[tuple] = 1\n",
    "\n",
    "clean_vocab = [(tuple[0], tuple[1], count) for tuple, count in counts.items()]\n",
    "print(len(clean_vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8658\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for tuple in clean_vocab:\n",
    "    if not tuple[0].isdigit():\n",
    "        vocab.append(tuple)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>realised</td>\n",
       "      <td>VBD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>civic</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>maintained</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>whatever</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8652</th>\n",
       "      <td>Starmer</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>bent</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>Neal</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>Lawson</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>cross-party</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>Compass</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  POS  Count\n",
       "8648     realised  VBD      1\n",
       "8649        civic   NN      1\n",
       "8650   maintained  VBN      1\n",
       "8651     whatever   IN      1\n",
       "8652      Starmer   NN      1\n",
       "8653         bent  VBN      1\n",
       "8654         Neal  NNP      1\n",
       "8655       Lawson  NNP      1\n",
       "8656  cross-party   JJ      1\n",
       "8657      Compass  NNP      1"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek = pd.DataFrame(vocab, columns=['Word', 'POS', 'Count'])\n",
    "peek.tail(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "1. find if there is a difference between proper nouns and other capitalised words and lower case words that don't need to be capitalised\n",
    "2. export to .csv without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_chars(s):\n",
    "#     return s.translate(str.maketrans(\" \", \" \", string.punctuation.replace(\"_\", \"\")))\n",
    "\n",
    "# clean_count = {replace_chars(k): v for k, v in counts.items()}\n",
    "# print(len(clean_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace(',', ' ').replace('.', ' '): v for k, v in counts.items()}\n",
    "\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k.replace('“', '').replace('”', '').replace('‘', '').replace('’', ''): v for k, v in clean_count.items()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with capitalized words (potentially proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isupper()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with sterling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"£\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with \"–\" as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0]== \"–\"}\n",
    "# # peek_currency = {k: v for k, v in clean_count.items() if k[0]== \"£\"}\n",
    "# print(len(clean_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove entries with digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_count = {k: v for k, v in clean_count.items() if len(k)>0 and not k[0].isdigit()}\n",
    "# print(len(clean_count))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek = pd.DataFrame.from_dict(clean_count, orient='index', columns=['count'])\n",
    "# peek.sort_values(\"count\").tail(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary = sorted([ (v,k) for k,v in counts.items()], reverse=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorted list reveals that further refinement is going to be needed: The most common are probably only marginally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many at the bottom of the list (those less used) are not grammatical words and they need to be cleaned up. For example removing words in parenthesis, with hashtags, numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocabulary[-1000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_counts = {k: v for k, v in counts.items() if not (k.startswith('#') \n",
    "# or k.startswith('(')\n",
    "# or k.startswith('$')\n",
    "# or k.startswith('£')\n",
    "# or k.startswith('\\''))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10181\n"
     ]
    }
   ],
   "source": [
    "# print(len(sorted_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067\n"
     ]
    }
   ],
   "source": [
    "# print(len(clean_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in list(clean_counts)[900:1000]:\n",
    "#     print (\"key {}, value {} \".format(x,  clean_counts[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [(k, v) for k, v in clean_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(data, columns=['key', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.sort_values(by='value', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbba1214f6436c1b9df455eb4b634c6f3489084cc9221bb041863e864fbbb981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
