{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Guardian Opinions: Text Classification and Bag-of-Words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outline:\n",
        "- Import and explore data\n",
        "- Apply text preprocessing techniques\n",
        "- -Implement the bag-of-words model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import and explore data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following data was collected using a Scrapy spider, found in this repository under /guardianscraper/guardianscraper/spiders/guardianspider.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>Liz Truss set out her grand plan to me – and i...</td>\n",
              "      <td>Katy Balls</td>\n",
              "      <td>“You’ve set the cat among the pigeons,” messag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>The Gareth Thomas case proves it: no one wins ...</td>\n",
              "      <td>James Greig</td>\n",
              "      <td>Few public figures alive today have done more ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>There’s no cycle of violence in Jerusalem – on...</td>\n",
              "      <td>Jalal Abukhater</td>\n",
              "      <td>Almost every day, the bulldozers are on the mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023/feb/06</td>\n",
              "      <td>The ‘leftwing economic establishment’ did not ...</td>\n",
              "      <td>Polly Toynbee</td>\n",
              "      <td>“This soul-searching has not been easy,” she w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>I have seen race hate in the US and UK and the...</td>\n",
              "      <td>Al Sharpton</td>\n",
              "      <td>I came to London more than 30 years ago to pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>As the detective who inspired TV’s Prime Suspe...</td>\n",
              "      <td>Jackie Malton</td>\n",
              "      <td>We have now heard for the first time from Davi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>Britain, we had a thing with Truss and Johnson...</td>\n",
              "      <td>Marina Hyde</td>\n",
              "      <td>Liz Truss is now eluded by two major types of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>Would I ditch a date after 51 minutes? I’ve wa...</td>\n",
              "      <td>Elle Hunt</td>\n",
              "      <td>Fifty-one minutes. It’s too long for a meeting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>As an ex police officer, this much is clear: a...</td>\n",
              "      <td>Steve White</td>\n",
              "      <td>The sentencing of David Carrick and the dreadf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023/feb/07</td>\n",
              "      <td>Jeremy Hunt says focus on the ‘economically in...</td>\n",
              "      <td>Frances Ryan</td>\n",
              "      <td>As the government lurches between screw-ups, s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date                                              title  \\\n",
              "0  2023/feb/07  Liz Truss set out her grand plan to me – and i...   \n",
              "1  2023/feb/07  The Gareth Thomas case proves it: no one wins ...   \n",
              "2  2023/feb/07  There’s no cycle of violence in Jerusalem – on...   \n",
              "3  2023/feb/06  The ‘leftwing economic establishment’ did not ...   \n",
              "4  2023/feb/07  I have seen race hate in the US and UK and the...   \n",
              "5  2023/feb/07  As the detective who inspired TV’s Prime Suspe...   \n",
              "6  2023/feb/07  Britain, we had a thing with Truss and Johnson...   \n",
              "7  2023/feb/07  Would I ditch a date after 51 minutes? I’ve wa...   \n",
              "8  2023/feb/07  As an ex police officer, this much is clear: a...   \n",
              "9  2023/feb/07  Jeremy Hunt says focus on the ‘economically in...   \n",
              "\n",
              "            author                                            article  \n",
              "0       Katy Balls  “You’ve set the cat among the pigeons,” messag...  \n",
              "1      James Greig  Few public figures alive today have done more ...  \n",
              "2  Jalal Abukhater  Almost every day, the bulldozers are on the mo...  \n",
              "3    Polly Toynbee  “This soul-searching has not been easy,” she w...  \n",
              "4      Al Sharpton  I came to London more than 30 years ago to pro...  \n",
              "5    Jackie Malton  We have now heard for the first time from Davi...  \n",
              "6      Marina Hyde  Liz Truss is now eluded by two major types of ...  \n",
              "7        Elle Hunt  Fifty-one minutes. It’s too long for a meeting...  \n",
              "8      Steve White  The sentencing of David Carrick and the dreadf...  \n",
              "9     Frances Ryan  As the government lurches between screw-ups, s...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./guardian_data.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'“You’ve set the cat among the pigeons,” messaged a Tory MP after my interview with Liz Truss dropped on Monday night. The former prime minister’s first spoken intervention since leaving office saw Truss offer little in the way of a mea culpa, and instead set out her plans to carve out a place for herself on the backbenches as a committed tax-cutter. “Obviously I’ve got more time available now to think about these things and make the argument and that’s what I want to do,” she said of her post-prime ministerial plans.Given Rishi Sunak and Jeremy Hunt are trying to lower expectations ahead of the spring budget (and the budget after that), it’s exactly the type of intervention the government would rather avoid. The chancellor has repeatedly suggested now is not the time for tax cuts – instead they will only come “when the time is right”. Sunak has frequently said bringing down inflation must come first. He said the public were “not idiots” and understood this. The implication? Some in his party are.There are plenty within the Tory party who would be inclined to agree. Since Truss broke her silence – just over three months after leaving Downing Street – with a 4-000-word essay in the Sunday Telegraph and now her interview with the Spectator, several of her parliamentary colleagues have been publicly critical. Caroline Nokes said “a period of silence would be helpful”, while the cabinet minister Grant Shapps has said Truss’s tax cuts were clearly the wrong approach. A former aide to Truss is similarly disobliging: “I don’t think now is the right time to speak. In the past, former prime ministers have found a charitable cause rather than diving straight back in.”However, Truss appears unperturbed by the criticism. Given her place in history as the shortest-serving prime minister, she was markedly upbeat during the 50-minute sit down. Perhaps though the difficulty of that seven-week premiership explains why one of the questions she was the quickest to respond to was: would she like to be prime minister again? The answer was a polite but firm no. While Truss’s critics will no doubt find relief in those comments, the bigger concern among her opponents within her party is the effect she could soon have on the ideological debate.Her return presents Sunak with trouble on several counts. First, there are senior Tories and ministers who worry that any intervention by Truss, regardless of whether it’s separate to or even critical of Sunak, will simply remind the public of a short-lived leadership they would like voters to forget. It makes it much harder for Sunak to turn the page with the public if his predecessors are still hanging around. But more than that, Truss still holds some sway in parts of the Tory party. Notably, her interventions so far have been more focused on a Conservative-minded audience than the public at large.Truss believes one of the reasons her premiership failed was a failure by people who hold her views – small-state, low-tax, free market – to make the argument. “Was I trying to fatten the pig on market day, maybe … there’s a long history of failing to make the case and that’s what I’m thinking now,” she said.On this point, there are plenty of Tory MPs who agree. There is a sense not just on the right of the party that, after more a decade in government, the party has lost touch with its core principles. It’s one of the main reasons she won the leadership contest in the summer. Although some MPs backed the then foreign secretary in the hope of a plum job from the bookies’ favourite, plenty more did so because they preferred her brand of true-blue radicalism on tax cuts to Sunak’s more modest managerialism.The ‘leftwing economic establishment’ did not bring Liz Truss down. Reality did | Polly ToynbeeRead moreIt means that a push by Truss or the new 40-strong Conservative Growth Group – led by two MPs who served as cabinet ministers in her government – has the potential to make life difficult for Sunak.Many of the MPs worried about such a push are more concerned not about the next 18 months, but about what may come after. As the Tories continue to trail Labour heavily in the polls, lots of MPs are more inclined to discuss the likely scale of defeat come the election rather than whether they can turn things around and win a fifth term. The scale of the defeat would be a big factor in the type of debate the Tories have in the event of a loss – and the candidate who succeeds as leader of the opposition.In the event of a big loss, expect figures such as Truss and former ministers like Jacob Rees-Mogg to argue of the need to return to a more purist low-tax agenda. It’s here that Truss’s interventions – of which there will be more in the coming weeks and months – could have the biggest impact.\\n Katy Balls is political editor of the Spectator\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_article = df.article.values[0]\n",
        "sample_article"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some text clean up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['article'] = df['article'].replace('\\n', '', regex=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outline:\n",
        "- Understand the bag of words model\n",
        "- Tokenization\n",
        "- Stop-word removal\n",
        "- Stemming"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Bag of words intuition"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Create a list of all the words in the articls\n",
        "2. Convert each article into vector counts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### some limitations:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   1. Possibly too many words\n",
        "   2. some words may occur too frequently\n",
        "   3. some words may occur very rarely or only once\n",
        "   4. A single word may have many forms (ex: go, gone, going; or bird vs. bird)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/juancarlos/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_tokenize = word_tokenize(df.article.values[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_text = []\n",
        "\n",
        "for text in df.article.values:\n",
        "    all_text.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50074\n"
          ]
        }
      ],
      "source": [
        "# join all text\n",
        "all_joined = ' '.join(all_text)\n",
        "full_tokens = word_tokenize(all_joined)\n",
        "print(len(full_tokens))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stop-word removal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "removing commonly-occurring words that offer little or no meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/juancarlos/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "english_stops = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\", \".join(english_stops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stops(tokens):\n",
        "  return[ word for word in tokens if word.lower() not in english_stops]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31076\n"
          ]
        }
      ],
      "source": [
        "stopless_tokens = remove_stops(full_tokens)\n",
        "\n",
        "print(len(stopless_tokens))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I need to remove all the punctuation ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23559\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "punctuation_list = list(string.punctuation)\n",
        "apostrophes = ['“', '’','”','‘','–']\n",
        "\n",
        "no_punctuation = [word for word in stopless_tokens if word not in punctuation_list and word not in apostrophes]\n",
        "\n",
        "print(len(no_punctuation))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stemming vs. Lemmatization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While stemming truncates variations of a word to a common 'stem' (sometimes this tem is not grammatical, i.e. 'decidedly' => 'decid'), Lemmatization finds the grammatical root word (i.e. \"love\" => \"love\", \"loving\" => \"love\", \"lovable\" => \"love\" ). Lemmatization finds the root word by using a dictionary, thus making it slow and heavy.\n",
        "\n",
        "I will opt for stemming here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer(language = 'english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "stemmed_text = [stemmer.stem(word) for word in no_punctuation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23559\n"
          ]
        }
      ],
      "source": [
        "print(len(stemmed_text))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bag-of-words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transform Text to Vectors using CountVectorizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is a module of scikit learn which converts a collection of text documents to a matrix of token counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorize = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize.fit(stemmed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorize.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_vocab = sorted([ (v,k) for k,v in vectorize.vocabulary_.items()], reverse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(5359, 'zoë'),\n",
              " (5358, 'zone'),\n",
              " (5357, 'zombie'),\n",
              " (5356, 'zombi'),\n",
              " (5355, 'zoe'),\n",
              " (5354, 'zero'),\n",
              " (5353, 'zeitung'),\n",
              " (5352, 'zdf'),\n",
              " (5351, 'zahawi'),\n",
              " (5350, 'youtub')]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_vocab[:10]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This approach doesn't suit my purpose because it returns personal names. Also, I am not sure the count is correct. I will attempt a new approach in a different notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dbba1214f6436c1b9df455eb4b634c6f3489084cc9221bb041863e864fbbb981"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
